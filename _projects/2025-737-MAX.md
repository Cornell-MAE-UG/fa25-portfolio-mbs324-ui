---
layout: project
title: 737 MAX Ethics Analysis
description: Analyze the Boeing 737 MAX crashes and response from an engineering ethics perspective. 
technologies: []
image: 
---

The Boeing 737 MAX crashes and subsequent response highlighted engineering ethics issues. I investigated the accidents and the part that Boeing, the FAA, the airlines, the pilots, and the maintance crew played, focusing on both the engineering decisions made by Boeing and how the accidents fit into a broader ethical context. 

Sources consulted:
The Boeing 737 MAX: Lessons for Engineering Ethics by Herket, Borenstein, and Miller, published 7/10/20

Boeing designed its 737 MAX with the desire to out-compete Airbus (A320neo), facing pressure from the airlines to do so. With that economic competition in mind, Boeing installed new, larger engines that were more powerful and fuel-efficient than those of the 737 NG. The new engines would also help them acheieve emissions targets. Since the plane was low to the ground, the engine placement was changed, which altered the flight characteristics. Note that the A320neo, a re-engine of the A320(ceo), did not have these issues since more ground clearance was available. Boeing wanted to keep the 737 MAX as similar as possible to the 737 NG so they could use the same type certificate and keep new training to a minimum, making the MAX more attractive to airlines. 

In order to account for changes to flight performance, Boeing engineers created the now-infamous "MCAS" software to prevent stall. The software, which was not fully and clearly explained to pilots, caused the aircraft to nose down if the AoA was too high. The software was only active when the autopilot was disengaged, and relied on input from a single AoA sensor even though the aircraft was equipped with two. 

Pilot Mark Forkner raised issues about MCAS but did not report them to the FAA, believing that the issues would be taken care of. Boeing engineers also raised issues, but they were not addressed. Engineer Curtis Ewbank raised an ethics complaint, but it was not resolved. While Boeing has had a strong safety and engineering record in the past, recent changes to corporate structure and management have encouraged separation between management and engineering, and more emphasis on profits over safety. Such corner-cutting measures were bound to catch up to them eventually. 

In October 2018, a 737 MAX operated by Indonesian airline Lion Air crashed after takeoff. As with many aviation accidents, there were a number of complicated and intertwined factors responsible for the crash. Firstly, a critical AoA sensor was not properly tested or maintained. Had the ground or maintenance crew caught this issue, the crash would not have occured. The pilots were not sufficiently informed of the MCAS or trained to fly with it. Pilots Forkner and Sullenberger have stated that the MCAS behaves unpredictably and presents in a confusing way, and additional training and information was needed. However, the Lion Air pilots did have checklists they could have used to recover the aircraft. Boeing engineers, thinking the MCAS unimportant, only relied on a single AoA sensor when they could have used two for redundancy. Even if maintenance had done everything perfectly, the AoA sensor still could have failed. This is simply negligent design. Boeing's decision to not tell the pilots about a software that alters flight performance when the autopilot was OFF was certainly unethical, and contributeed to the crashes. Had they not pushed for similarity at all costs, perhaps they would have been more transparent. Finally, the FAA had delegated much of their inspection and certification power to Boeing itself, trusting them to check their own work. While more efficient, this arrangement is ethically suspect: how could Boeing be impartial in that situation? 

After the Lion Air crash, Boeing told airlines that pilots could use the runway stabilizer checklist in the case of MCAS issues, and released an update to the MCAS software. However, in March 2019, another 737 MAX, operated by Ethiopian Airlines, crashed after takeoff. This incident resulted in the aircraft being grounded. 

Due to AoA issues, MCAS activated when the aircraft was at low altitude, and the aircraft descended. The pilots were aware of the MCAS issues and successfully turned it off, but it was too late. Turning off MCAS also turned off electrical controls; unable to pull out of the dive. According to Ethiopian authorities (ECAA), the pilots had followed proper procedures, but the plane still crashed. Like the previous crash, AoA sensor issues and MCAS had caused the horizontal stabilizer to get stuck, forcing the aircraft to descend. The ECAA also stated that Boeing did not sufficiently train pilots to work with the new software, and the lack of redundancy in the software was a major safety flaw. However, the NTSB and BEA argued that pilot error also played a role, and the pilots had in fact been trained on how to recover the aircraft in this situation. Pilot error and poor crew resource management had contributed to a past Ethiopian Airlines crash, Flight 409. Lion Air has also had issues with pilot error (Flight 904). 

Ultimately, these crashes were caused by a combination of maintenance errors (Lion Air), pilot error and poor crew resource management (Lion Air and Ethiopian Airlines and their pilots), poor design choices, lack of transparency, lack of training materials and information, and a profits-over-safety attitude (Boeing), and a lack of regulatory oversight (FAA). According to engineering ethics, Boeing should always put safety first. To achieve this, Boeing should be more transparent, and put less pressure on engineers to achieve unrealistic deadlines and goals. Engineers should be responsible and honest, and should refuse to sign off on an unsafe design even if it costs them their job. The FAA should be independent from the companies it is certifying; if it isn't equipped to do inspections itself, it should receive more funding to do so. The airlines need to train their pilots better and discourage cost-cutting measures. The pilots need to follow their training and practice good CRM, especially in a crisis. Finally, maintenance needs to follow proper testing and repair procedures and not cut corners. 